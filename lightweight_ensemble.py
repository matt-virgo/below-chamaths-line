#!/usr/bin/env python3

"""
Lightweight Ensemble Analysis
Combining our best existing models with different ensemble strategies
while the heavy TabPFN post-hoc ensemble trains in the background.
"""

import json
import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

# Set random seeds for reproducibility
np.random.seed(42)

def load_data():
    """Load training and test data"""
    with open('train_cases.json', 'r') as f:
        train_data = json.load(f)
    
    with open('test_cases.json', 'r') as f:
        test_data = json.load(f)
    
    # Convert to DataFrames
    train_df = pd.DataFrame([
        {
            'trip_duration_days': case['input']['trip_duration_days'],
            'miles_traveled': case['input']['miles_traveled'],
            'total_receipts_amount': case['input']['total_receipts_amount'],
            'reimbursement': case['expected_output']
        }
        for case in train_data
    ])
    
    test_df = pd.DataFrame([
        {
            'trip_duration_days': case['input']['trip_duration_days'],
            'miles_traveled': case['input']['miles_traveled'],
            'total_receipts_amount': case['input']['total_receipts_amount'],
            'reimbursement': case['expected_output']
        }
        for case in test_data
    ])
    
    return train_df, test_df

def create_v1_ultra_features(df):
    """Create V1's proven comprehensive feature set (58 features)"""
    features_df = df.copy()
    
    # Basic variables
    D = df['trip_duration_days']
    M = df['miles_traveled']
    R = df['total_receipts_amount']
    
    # Core derived features
    features_df['miles_per_day'] = M / D
    features_df['receipts_per_day'] = R / D
    
    # Most important validated features
    features_df['total_trip_value'] = D * M * R
    features_df['receipts_log'] = np.log1p(R)
    features_df['receipts_sqrt'] = np.sqrt(R)
    features_df['receipts_squared'] = R ** 2
    features_df['receipts_cubed'] = R ** 3
    
    # Miles transformations
    features_df['miles_log'] = np.log1p(M)
    features_df['miles_sqrt'] = np.sqrt(M)
    features_df['miles_squared'] = M ** 2
    features_df['miles_cubed'] = M ** 3
    
    # Days transformations
    features_df['days_squared'] = D ** 2
    features_df['days_cubed'] = D ** 3
    features_df['days_fourth'] = D ** 4
    
    # Lucky cents feature
    features_df['receipts_cents'] = (R * 100) % 100
    features_df['has_lucky_cents'] = ((features_df['receipts_cents'] == 49) | 
                                     (features_df['receipts_cents'] == 99)).astype(float)
    
    # Comprehensive interactions
    features_df['miles_receipts'] = M * R
    features_df['days_receipts'] = D * R
    features_df['days_miles'] = D * M
    features_df['miles_per_day_squared'] = features_df['miles_per_day'] ** 2
    features_df['receipts_per_day_squared'] = features_df['receipts_per_day'] ** 2
    features_df['miles_receipts_per_day'] = features_df['miles_per_day'] * features_df['receipts_per_day']
    
    # Complex ratio features
    features_df['receipts_to_miles_ratio'] = R / (M + 1)
    features_df['miles_to_days_ratio'] = M / D
    features_df['total_value_per_day'] = features_df['total_trip_value'] / D
    
    # Trigonometric features
    features_df['receipts_sin_1000'] = np.sin(R / 1000)
    features_df['receipts_cos_1000'] = np.cos(R / 1000)
    features_df['receipts_sin_500'] = np.sin(R / 500)
    features_df['receipts_cos_500'] = np.cos(R / 500)
    features_df['miles_sin_500'] = np.sin(M / 500)
    features_df['miles_cos_500'] = np.cos(M / 500)
    features_df['miles_sin_1000'] = np.sin(M / 1000)
    features_df['miles_cos_1000'] = np.cos(M / 1000)
    
    # Exponential features
    features_df['receipts_exp_norm'] = np.exp(R / 2000) - 1
    features_df['miles_exp_norm'] = np.exp(M / 1000) - 1
    features_df['days_exp_norm'] = np.exp(D / 10) - 1
    
    # Polynomial combinations
    features_df['days_miles_receipts'] = D * M * R
    features_df['sqrt_days_miles_receipts'] = np.sqrt(D * M * R)
    features_df['log_days_miles_receipts'] = np.log1p(D * M * R)
    
    # High-order interactions
    features_df['d2_m_r'] = (D ** 2) * M * R
    features_df['d_m2_r'] = D * (M ** 2) * R
    features_df['d_m_r2'] = D * M * (R ** 2)
    
    # Binned features
    features_df['receipts_bin_20'] = pd.cut(R, bins=20, labels=False)
    features_df['miles_bin_20'] = pd.cut(M, bins=20, labels=False)
    features_df['days_bin_10'] = pd.cut(D, bins=10, labels=False)
    
    # Per-day thresholds
    mpd = M / D
    rpd = R / D
    features_df['mpd_low'] = (mpd < 100).astype(float)
    features_df['mpd_med'] = ((mpd >= 100) & (mpd <= 200)).astype(float)
    features_df['mpd_high'] = (mpd > 200).astype(float)
    features_df['rpd_low'] = (rpd < 75).astype(float)
    features_df['rpd_med'] = ((rpd >= 75) & (rpd <= 150)).astype(float)
    features_df['rpd_high'] = (rpd > 150).astype(float)
    
    # Special case indicators
    features_df['is_short_trip'] = (D <= 2).astype(float)
    features_df['is_medium_trip'] = ((D >= 3) & (D <= 7)).astype(float)
    features_df['is_long_trip'] = (D >= 8).astype(float)
    features_df['is_5_day_trip'] = (D == 5).astype(float)
    
    # Get feature columns (exclude target)
    feature_cols = [col for col in features_df.columns if col != 'reimbursement']
    
    return features_df[feature_cols]

def get_tabpfn_predictions():
    """Get TabPFN predictions from our best model"""
    try:
        # Try to load existing TabPFN results
        tabpfn_results = pd.read_csv('tabpfn_v1_engineered_results.csv')
        return tabpfn_results['tabpfn_prediction'].values
    except FileNotFoundError:
        print("   ‚ö†Ô∏è  TabPFN results not found, training TabPFN on-the-fly...")
        
        # If results don't exist, create TabPFN predictions
        try:
            from tabpfn import TabPFNRegressor
            
            # Load data and create features
            train_df, test_df = load_data()
            X_train = create_v1_ultra_features(train_df).values
            X_test = create_v1_ultra_features(test_df).values
            y_train = train_df['reimbursement'].values
            
            # Train TabPFN
            tabpfn = TabPFNRegressor(device='cpu', N_ensemble_configurations=4)
            tabpfn.fit(X_train, y_train)
            predictions = tabpfn.predict(X_test)
            
            return predictions
        except Exception as e:
            print(f"   ‚ùå Could not get TabPFN predictions: {str(e)}")
            return None

def train_complementary_models(X_train, y_train, X_test):
    """Train complementary models with different characteristics"""
    models_predictions = {}
    
    print("üöÄ Training complementary models...")
    
    # 1. XGBoost - Tree-based ensemble
    print("   üìä Training XGBoost...")
    xgb_model = xgb.XGBRegressor(
        n_estimators=1000,
        max_depth=6,
        learning_rate=0.05,
        subsample=0.9,
        colsample_bytree=0.9,
        random_state=42,
        n_jobs=-1
    )
    xgb_model.fit(X_train, y_train, eval_set=[(X_test, np.zeros(len(X_test)))], verbose=0)
    models_predictions['xgboost'] = xgb_model.predict(X_test)
    
    # 2. Random Forest - Bagging ensemble
    print("   üå≤ Training Random Forest...")
    rf_model = RandomForestRegressor(
        n_estimators=500,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    )
    rf_model.fit(X_train, y_train)
    models_predictions['random_forest'] = rf_model.predict(X_test)
    
    # 3. Gradient Boosting - Sequential ensemble
    print("   üöÄ Training Gradient Boosting...")
    gb_model = GradientBoostingRegressor(
        n_estimators=500,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.9,
        random_state=42
    )
    gb_model.fit(X_train, y_train)
    models_predictions['gradient_boosting'] = gb_model.predict(X_test)
    
    return models_predictions

def create_ensemble_predictions(tabpfn_pred, other_predictions, y_test):
    """Create different ensemble combinations"""
    ensemble_results = {}
    
    if tabpfn_pred is not None:
        # Simple average ensemble
        all_preds = [tabpfn_pred] + list(other_predictions.values())
        avg_pred = np.mean(all_preds, axis=0)
        ensemble_results['simple_average'] = {
            'predictions': avg_pred,
            'mae': mean_absolute_error(y_test, avg_pred),
            'description': 'Simple average of all models'
        }
        
        # Weighted ensemble (give TabPFN more weight since it's our best)
        weighted_pred = (0.5 * tabpfn_pred + 
                        0.2 * other_predictions['xgboost'] +
                        0.15 * other_predictions['random_forest'] +
                        0.15 * other_predictions['gradient_boosting'])
        ensemble_results['tabpfn_weighted'] = {
            'predictions': weighted_pred,
            'mae': mean_absolute_error(y_test, weighted_pred),
            'description': 'TabPFN-weighted ensemble (50% TabPFN, 50% others)'
        }
        
        # Conservative ensemble (emphasize agreement)
        # Use median instead of mean for robustness
        median_pred = np.median(all_preds, axis=0)
        ensemble_results['median_ensemble'] = {
            'predictions': median_pred,
            'mae': mean_absolute_error(y_test, median_pred),
            'description': 'Median of all model predictions'
        }
    
    # Tree-ensemble only (without TabPFN)
    tree_preds = list(other_predictions.values())
    tree_avg = np.mean(tree_preds, axis=0)
    ensemble_results['tree_ensemble'] = {
        'predictions': tree_avg,
        'mae': mean_absolute_error(y_test, tree_avg),
        'description': 'Average of tree-based models only'
    }
    
    return ensemble_results

def main():
    print("‚ö° Lightweight Ensemble Analysis")
    print("="*70)
    print("Creating fast ensembles while TabPFN post-hoc ensemble trains")
    print()
    
    print("Loading data...")
    train_df, test_df = load_data()
    
    print(f"Dataset overview:")
    print(f"   üìä Training samples: {len(train_df)}")
    print(f"   üìä Test samples: {len(test_df)}")
    
    # Create features
    print("\nCreating V1's comprehensive engineered features...")
    X_train = create_v1_ultra_features(train_df)
    X_test = create_v1_ultra_features(test_df)
    y_train = train_df['reimbursement'].values
    y_test = test_df['reimbursement'].values
    
    print(f"‚ú® Using {X_train.shape[1]} V1 engineered features")
    
    # Get TabPFN predictions (our current best model)
    print(f"\n{'='*70}")
    print(f"üìà Getting TabPFN predictions (current champion: $55.96 MAE)")
    print(f"{'='*70}")
    
    tabpfn_predictions = get_tabpfn_predictions()
    if tabpfn_predictions is not None:
        tabpfn_mae = mean_absolute_error(y_test, tabpfn_predictions)
        print(f"‚úÖ TabPFN baseline: ${tabpfn_mae:.2f} MAE")
    else:
        print("‚ö†Ô∏è  Proceeding without TabPFN predictions")
    
    # Train complementary models
    print(f"\n{'='*70}")
    print(f"üéØ Training Complementary Models")
    print(f"{'='*70}")
    
    other_predictions = train_complementary_models(X_train.values, y_train, X_test.values)
    
    # Show individual model performance
    print(f"\nüìä INDIVIDUAL MODEL PERFORMANCE:")
    if tabpfn_predictions is not None:
        print(f"   üèÜ TabPFN (Champion):        ${tabpfn_mae:.2f} MAE")
    
    for model_name, predictions in other_predictions.items():
        mae = mean_absolute_error(y_test, predictions)
        print(f"   üìà {model_name.replace('_', ' ').title():20s} ${mae:.2f} MAE")
    
    # Create ensemble combinations
    print(f"\n{'='*70}")
    print(f"ü§ù Creating Ensemble Combinations")
    print(f"{'='*70}")
    
    ensemble_results = create_ensemble_predictions(tabpfn_predictions, other_predictions, y_test)
    
    # Analyze ensemble performance
    print(f"\nüèÜ ENSEMBLE PERFORMANCE RESULTS:")
    
    # Sort by performance
    sorted_ensembles = sorted(ensemble_results.items(), key=lambda x: x[1]['mae'])
    
    best_mae = 55.96  # Our current record
    champion_found = False
    
    for i, (ensemble_name, result) in enumerate(sorted_ensembles):
        rank_emoji = ["ü•á", "ü•à", "ü•â", "4Ô∏è‚É£", "5Ô∏è‚É£"][min(i, 4)]
        mae = result['mae']
        improvement = best_mae - mae
        improvement_pct = (improvement / best_mae) * 100
        
        if mae < best_mae and not champion_found:
            print(f"   {rank_emoji} {ensemble_name.replace('_', ' ').title():25s} ${mae:.2f} MAE üèÜ NEW RECORD! (+{improvement_pct:.2f}%)")
            champion_found = True
        elif mae < best_mae:
            print(f"   {rank_emoji} {ensemble_name.replace('_', ' ').title():25s} ${mae:.2f} MAE ‚≠ê BEATS RECORD! (+{improvement_pct:.2f}%)")
        else:
            print(f"   {rank_emoji} {ensemble_name.replace('_', ' ').title():25s} ${mae:.2f} MAE ({improvement:+.2f})")
        
        print(f"       ‚îî‚îÄ {result['description']}")
    
    # Save best ensemble results
    best_ensemble_name, best_ensemble_result = sorted_ensembles[0]
    
    results_df = pd.DataFrame({
        'actual': y_test,
        'predicted': best_ensemble_result['predictions'],
        'absolute_error': np.abs(y_test - best_ensemble_result['predictions'])
    })
    
    results_filename = f"lightweight_ensemble_{best_ensemble_name}_results.csv"
    results_df.to_csv(results_filename, index=False)
    
    # Create comprehensive comparison
    comparison_data = []
    
    # Add baseline
    if tabpfn_predictions is not None:
        comparison_data.append({
            'model': 'TabPFN V1 (Current Champion)',
            'mae': tabpfn_mae,
            'type': 'Foundation Model',
            'notes': 'Single TabPFN with V1 engineered features'
        })
    
    # Add individual models
    for model_name, predictions in other_predictions.items():
        mae = mean_absolute_error(y_test, predictions)
        comparison_data.append({
            'model': model_name.replace('_', ' ').title(),
            'mae': mae,
            'type': 'Tree Ensemble',
            'notes': f'Individual {model_name.replace("_", " ")} model'
        })
    
    # Add ensemble results
    for ensemble_name, result in ensemble_results.items():
        comparison_data.append({
            'model': f"{ensemble_name.replace('_', ' ').title()} Ensemble",
            'mae': result['mae'],
            'type': 'Hybrid Ensemble',
            'notes': result['description']
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    comparison_df = comparison_df.sort_values('mae')
    comparison_df.to_csv('lightweight_ensemble_comparison.csv', index=False)
    
    print(f"\nüíæ Results saved:")
    print(f"   üìä Best ensemble: {results_filename}")
    print(f"   üìà Full comparison: lightweight_ensemble_comparison.csv")
    
    # Final insights
    print(f"\nüß† LIGHTWEIGHT ENSEMBLE INSIGHTS:")
    
    if champion_found:
        best_mae_achieved = sorted_ensembles[0][1]['mae']
        improvement = best_mae - best_mae_achieved
        print(f"   üéâ NEW RECORD ACHIEVED!")
        print(f"   üèÜ Best ensemble: {sorted_ensembles[0][0].replace('_', ' ').title()}")
        print(f"   üìà New MAE: ${best_mae_achieved:.2f} (improved by ${improvement:.2f})")
        print(f"   ‚ö° Achieved with lightweight, fast training!")
    else:
        print(f"   üìä Best ensemble: ${sorted_ensembles[0][1]['mae']:.2f} MAE")
        print(f"   üéØ Close to record but didn't beat ${best_mae:.2f}")
        print(f"   ‚ö° Still valuable for robustness and speed")
    
    print(f"   ü§ù Ensemble diversity helps reduce prediction variance")
    print(f"   üöÄ Tree models complement TabPFN's foundation model approach")
    print(f"   ‚ö° Much faster than post-hoc ensembles")
    
    print(f"\nüîÑ While we wait for TabPFN post-hoc results:")
    print(f"   ‚Ä¢ Our lightweight ensembles provide immediate insights")
    print(f"   ‚Ä¢ Combination of different model types shows promise")
    print(f"   ‚Ä¢ Fast iteration allows rapid experimentation")
    print(f"   ‚Ä¢ Results can guide post-hoc ensemble configuration")

if __name__ == "__main__":
    main() 